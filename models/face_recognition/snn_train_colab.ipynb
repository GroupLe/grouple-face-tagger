{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7pr-1sOH7ahq",
    "outputId": "ad53fb3b-a75b-4f08-a873-ffa401f4cdb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'grouple-face-tagger'...\n",
      "remote: Enumerating objects: 397, done.\u001b[K\n",
      "remote: Counting objects: 100% (397/397), done.\u001b[K\n",
      "remote: Compressing objects: 100% (291/291), done.\u001b[K\n",
      "remote: Total 397 (delta 142), reused 326 (delta 79), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (397/397), 13.88 MiB | 26.56 MiB/s, done.\n",
      "Resolving deltas: 100% (142/142), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/GroupLe/grouple-face-tagger/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ckJ4PzSXfWlV"
   },
   "outputs": [],
   "source": [
    "!cd grouple-face-tagger && touch __init__.py\n",
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9uFJ1ZbsgBUo",
    "outputId": "48ad367d-5ab9-44f3-c7c2-e4ec017a504a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KgVwrOkThMHa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "import wandb\n",
    "# import sys\n",
    "# sys.path.insert(0, \"grouple-face-tagger/models/face_detection/\")\n",
    "from snn_model.datasets import TripletPathDataset\n",
    "from snn_model.model import EmbeddingNet, TripletNet\n",
    "from snn_model.functions import accuracy\n",
    "from snn_model.transformations import EmptyTransformation\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xUAEBGBfiosg"
   },
   "outputs": [],
   "source": [
    "root = Path('../../data/face_detection/processed_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70808zrBhUz2",
    "outputId": "da958fce-e037-4645-a465-34611672d9db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1659\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "filecount=0\n",
    "for dirpath, dirs, files in os.walk(root):\n",
    "    for filename in files:\n",
    "        filecount+=1\n",
    "print(filecount)\n",
    "print(len(os.listdir(root)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "H1DEwYBdi6cY"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "composed = torchvision.transforms.Compose([T.ToTensor(),\n",
    "                                           T.Resize((128, 128)),\n",
    "                                           T.RandomChoice((T.ColorJitter(0.05, 0.05, 0.05),\n",
    "                                                          T.RandomRotation(degrees=(0, 30)),\n",
    "                                                          EmptyTransformation(),\n",
    "                                                          EmptyTransformation(),\n",
    "                                                          EmptyTransformation()))])\n",
    "                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GOiTGCaEi70o",
    "outputId": "a0f930cc-e83c-4aa3-cf45-4b2885fbaedb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:04,  4.96it/s]\n"
     ]
    }
   ],
   "source": [
    "siamse_dataset = TripletPathDataset(Path(root), transform = composed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "22f9sc6O9biB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1327\n",
      "331\n"
     ]
    }
   ],
   "source": [
    "print(round(len(siamse_dataset)*0.8))\n",
    "print(int(len(siamse_dataset)*0.2))\n",
    "\n",
    "siamse_dataset_train, siamse_dataset_test = torch.utils.data.random_split(siamse_dataset,\n",
    "                                                                         (round(len(siamse_dataset)*0.8),\n",
    "                                                                          round(len(siamse_dataset)*0.2)))\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 100\n",
    "train_dl = DataLoader(siamse_dataset_train, batch_size = batch_size, shuffle = True)\n",
    "test_dl = DataLoader(siamse_dataset_test, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_net = EmbeddingNet()\n",
    "model = TripletNet(embedding_net)\n",
    "criterion = nn.TripletMarginLoss(margin=1, p=2)\n",
    "optimizer = torch.optim.Adagrad(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "# wandb.login(host='wandb.ai' relogin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Optimizer.state_dict of Adagrad (\n",
       "Parameter Group 0\n",
       "    eps: 1e-10\n",
       "    initial_accumulator_value: 0\n",
       "    lr: 0.01\n",
       "    lr_decay: 0\n",
       "    weight_decay: 0\n",
       ")>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: metpinc (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">fluent-surf-37</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/metpinc/triplet_siamse_network\" target=\"_blank\">https://wandb.ai/metpinc/triplet_siamse_network</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/metpinc/triplet_siamse_network/runs/f1ggnxv0\" target=\"_blank\">https://wandb.ai/metpinc/triplet_siamse_network/runs/f1ggnxv0</a><br/>\n",
       "                Run data is saved locally in <code>C:\\may\\ML\\GroupLe\\grouple\\models\\face_detection\\wandb\\run-20210724_232909-f1ggnxv0</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"triplet_siamse_network\", config={\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"architecture\": \"SNN\"\n",
    "})\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 0\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\май\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\autograd\\__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [0/14] acc 0.76 loss 0.7518860697746277\n",
      "  [1/14] acc 0.75 loss 1.3860619068145752\n",
      "  [2/14] acc 0.65 loss 1.3839036226272583\n",
      "  [3/14] acc 0.61 loss 1.6354833841323853\n",
      "  [4/14] acc 0.69 loss 0.9536917805671692\n",
      "  [5/14] acc 0.7 loss 0.9747981429100037\n",
      "  [6/14] acc 0.75 loss 0.6950533986091614\n",
      "  [7/14] acc 0.77 loss 0.55531907081604\n",
      "  [8/14] acc 0.84 loss 0.486968070268631\n",
      "  [9/14] acc 0.77 loss 0.6205918788909912\n",
      "  [10/14] acc 0.76 loss 0.6764528751373291\n",
      "  [11/14] acc 0.82 loss 0.4739980399608612\n",
      "  [12/14] acc 0.78 loss 0.6145699620246887\n",
      "  [13/14] acc 0.7407407407407407 loss 0.5311856865882874\n",
      "train accuracy:  0.7421957671957672\n",
      "train loss:  tensor(0.8386, grad_fn=<DivBackward0>)\n",
      "test\n",
      "  [0/14] acc 0.66 loss 1.4268813133239746\n",
      "  [1/14] acc 0.72 loss 0.9612684845924377\n",
      "  [2/14] acc 0.71 loss 1.1484047174453735\n",
      "  [3/14] acc 0.78125 loss 0.7590048313140869\n",
      "test accuracy:  0.7178125\n",
      "\n",
      "\n",
      "Epoch 1\n",
      "train\n",
      "  [0/14] acc 0.77 loss 0.8372530341148376\n",
      "  [1/14] acc 0.77 loss 0.5707618594169617\n",
      "  [2/14] acc 0.84 loss 0.38544541597366333\n",
      "  [3/14] acc 0.75 loss 0.6083748936653137\n",
      "  [4/14] acc 0.81 loss 0.568727970123291\n",
      "  [5/14] acc 0.74 loss 0.8805966377258301\n",
      "  [6/14] acc 0.75 loss 0.513541579246521\n",
      "  [7/14] acc 0.87 loss 0.3688566982746124\n",
      "  [8/14] acc 0.77 loss 0.5361557602882385\n",
      "  [9/14] acc 0.73 loss 0.6262692213058472\n",
      "  [10/14] acc 0.86 loss 0.3377353250980377\n",
      "  [11/14] acc 0.87 loss 0.4114863872528076\n",
      "  [12/14] acc 0.8 loss 0.5571133494377136\n",
      "  [13/14] acc 0.6666666666666666 loss 0.7651419639587402\n",
      "train accuracy:  0.7854761904761904\n",
      "train loss:  tensor(0.5691, grad_fn=<DivBackward0>)\n",
      "test\n",
      "  [0/14] acc 0.76 loss 0.7363955974578857\n",
      "  [1/14] acc 0.76 loss 0.7099658250808716\n",
      "  [2/14] acc 0.74 loss 0.841411292552948\n",
      "  [3/14] acc 0.78125 loss 0.34817224740982056\n",
      "test accuracy:  0.7603125\n",
      "\n",
      "\n",
      "Epoch 2\n",
      "train\n",
      "  [0/14] acc 0.73 loss 0.702909529209137\n",
      "  [1/14] acc 0.78 loss 0.45576220750808716\n",
      "  [2/14] acc 0.83 loss 0.3837083578109741\n",
      "  [3/14] acc 0.87 loss 0.3812364339828491\n",
      "  [4/14] acc 0.81 loss 0.46142467856407166\n",
      "  [5/14] acc 0.83 loss 0.48711562156677246\n",
      "  [6/14] acc 0.79 loss 0.5045576095581055\n",
      "  [7/14] acc 0.88 loss 0.2591085135936737\n",
      "  [8/14] acc 0.83 loss 0.32056769728660583\n",
      "  [9/14] acc 0.82 loss 0.388977974653244\n",
      "  [10/14] acc 0.8 loss 0.5470292568206787\n",
      "  [11/14] acc 0.85 loss 0.35966140031814575\n",
      "  [12/14] acc 0.82 loss 0.43267932534217834\n",
      "  [13/14] acc 0.8888888888888888 loss 0.36049529910087585\n",
      "train accuracy:  0.8234920634920635\n",
      "train loss:  tensor(0.4318, grad_fn=<DivBackward0>)\n",
      "test\n",
      "  [0/14] acc 0.77 loss 0.5107266902923584\n",
      "  [1/14] acc 0.88 loss 0.357115238904953\n",
      "  [2/14] acc 0.85 loss 0.39274269342422485\n",
      "  [3/14] acc 0.71875 loss 0.6403744220733643\n",
      "test accuracy:  0.8046875\n",
      "\n",
      "\n",
      "Epoch 3\n",
      "train\n",
      "  [0/14] acc 0.84 loss 0.4173731505870819\n",
      "  [1/14] acc 0.76 loss 0.5386226773262024\n",
      "  [2/14] acc 0.86 loss 0.39370954036712646\n",
      "  [3/14] acc 0.84 loss 0.35503360629081726\n",
      "  [4/14] acc 0.84 loss 0.45410415530204773\n",
      "  [5/14] acc 0.84 loss 0.39073342084884644\n",
      "  [6/14] acc 0.93 loss 0.2323846071958542\n",
      "  [7/14] acc 0.81 loss 0.39372044801712036\n",
      "  [8/14] acc 0.88 loss 0.3205324113368988\n",
      "  [9/14] acc 0.9 loss 0.31844285130500793\n",
      "  [10/14] acc 0.86 loss 0.3946983814239502\n",
      "  [11/14] acc 0.91 loss 0.24788780510425568\n",
      "  [12/14] acc 0.84 loss 0.42912623286247253\n",
      "  [13/14] acc 0.8518518518518519 loss 0.27790898084640503\n",
      "train accuracy:  0.8544179894179894\n",
      "train loss:  tensor(0.3689, grad_fn=<DivBackward0>)\n",
      "test\n",
      "  [0/14] acc 0.83 loss 0.384517103433609\n",
      "  [1/14] acc 0.81 loss 0.37361544370651245\n",
      "  [2/14] acc 0.84 loss 0.4110974967479706\n",
      "  [3/14] acc 0.9375 loss 0.23092061281204224\n",
      "test accuracy:  0.854375\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "train\n",
      "  [0/14] acc 0.9 loss 0.3304029107093811\n",
      "  [1/14] acc 0.87 loss 0.30146822333335876\n",
      "  [2/14] acc 0.83 loss 0.3573143482208252\n",
      "  [3/14] acc 0.87 loss 0.2901676595211029\n",
      "  [4/14] acc 0.93 loss 0.2303955852985382\n",
      "  [5/14] acc 0.85 loss 0.4297408163547516\n",
      "  [6/14] acc 0.87 loss 0.3662830591201782\n",
      "  [7/14] acc 0.85 loss 0.32418468594551086\n",
      "  [8/14] acc 0.92 loss 0.22039298713207245\n",
      "  [9/14] acc 0.87 loss 0.29868796467781067\n",
      "  [10/14] acc 0.9 loss 0.30633747577667236\n",
      "  [11/14] acc 0.92 loss 0.21632996201515198\n",
      "  [12/14] acc 0.86 loss 0.36979812383651733\n",
      "  [13/14] acc 0.9259259259259259 loss 0.32547512650489807\n",
      "train accuracy:  0.8832804232804233\n",
      "train loss:  tensor(0.3119, grad_fn=<DivBackward0>)\n",
      "test\n",
      "  [0/14] acc 0.84 loss 0.40402212738990784\n",
      "  [1/14] acc 0.8 loss 0.4003690779209137\n",
      "  [2/14] acc 0.89 loss 0.30642327666282654\n",
      "  [3/14] acc 0.90625 loss 0.21107392013072968\n",
      "test accuracy:  0.8590625000000001\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "train\n",
      "  [0/14] acc 0.91 loss 0.2727721333503723\n",
      "  [1/14] acc 0.87 loss 0.2709249258041382\n",
      "  [2/14] acc 0.91 loss 0.27208787202835083\n",
      "  [3/14] acc 0.87 loss 0.32696643471717834\n",
      "  [4/14] acc 0.9 loss 0.2803596258163452\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    print('\\n\\nEpoch', epoch)\n",
    "\n",
    "    print('train')\n",
    "    \n",
    "    train_loss_history = []\n",
    "    train_accuracy_history = []\n",
    "\n",
    "    test_accuracy_history = []\n",
    "    test_loss_history = []\n",
    "    \n",
    "    for i, (anchor, positive, negative) in (enumerate(train_dl)):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = model.forward(anchor, positive, negative)\n",
    "        pred_anchor, pred_positive, pred_negative = pred\n",
    "        loss = criterion(pred_anchor, pred_positive, pred_negative)\n",
    "\n",
    "        loss.backward() #count gradients\n",
    "        optimizer.step() #update weights\n",
    "        scheduler.step(loss)\n",
    "\n",
    "        cur_accuracy = accuracy(pred_anchor, pred_positive, pred_negative)\n",
    "        print(f'  [{i}/{len(train_dl)}] acc {cur_accuracy} loss {loss}')\n",
    "        \n",
    "        train_accuracy_history.append(cur_accuracy)\n",
    "        train_loss_history.append(loss)\n",
    "        wandb.log({\"train/accuracy\": cur_accuracy, \"train/loss\": loss})\n",
    "\n",
    "    print('train accuracy: ', mean(train_accuracy_history))\n",
    "    print('train loss: ', sum(train_loss_history)/len(train_loss_history))\n",
    "\n",
    "\n",
    "    print('test')\n",
    "    with torch.no_grad():\n",
    "        for i, (anchor, positive, negative) in enumerate(test_dl):\n",
    "            pred = model.forward(anchor, positive, negative)\n",
    "            pred_anchor, pred_positive, pred_negative = pred\n",
    "            loss = criterion(pred_anchor, pred_positive, pred_negative)\n",
    "            cur_accuracy = accuracy(pred_anchor, pred_positive, pred_negative)\n",
    "            test_accuracy_history.append(cur_accuracy)\n",
    "            wandb.log({\"test/accuracy\":cur_accuracy})\n",
    "            wandb.log({\"test/loss\": loss})\n",
    "            print(f'  [{i}/{len(train_dl)}] acc {cur_accuracy} loss {loss}')\n",
    "            \n",
    "    print('test accuracy: ', mean(test_accuracy_history))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as F\n",
    "pic0 = F.to_pil_image(siamse_dataset[0][0])\n",
    "pic1 = F.to_pil_image(siamse_dataset[0][1])\n",
    "pic2 = F.to_pil_image(siamse_dataset[0][2])\n",
    "pics_pool = [pic1, pic2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:01,  1.64it/s]\n",
      "2it [00:01,  1.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_similars(pic0, pics_pool)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "snn_train_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
